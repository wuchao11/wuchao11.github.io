<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="you never konw what&apos;s the next">
<meta property="og:type" content="website">
<meta property="og:title" content="codingwc&#39;s blog">
<meta property="og:url" content="http://justcodingwc.top/index.html">
<meta property="og:site_name" content="codingwc&#39;s blog">
<meta property="og:description" content="you never konw what&apos;s the next">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="codingwc&#39;s blog">
<meta name="twitter:description" content="you never konw what&apos;s the next">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://justcodingwc.top/">





  <title>codingwc's blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">codingwc's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">life is short just coding</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2019/06/01/论婚姻/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/01/论婚姻/" itemprop="url">论婚姻</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-01T14:00:05+08:00">
                2019-06-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="我所理解的婚姻"><a href="#我所理解的婚姻" class="headerlink" title="我所理解的婚姻"></a>我所理解的婚姻</h3><p>​    婚姻就是两个人在一块，柴米油盐酱醋茶，计算好生活所需的财力物力，以及生子照顾老人。事实上，和恋爱的状态也没什么区别。无论是恋爱还是婚姻，最好势均力敌，伴侣太弱了，心生嫌弃，太强了，又会心生畏惧。当然了，现实中大多数人的家庭背景并不一致，也有相差很远的恋爱了结婚了，例如马克思和他的恋人。他们最好的状态就是成为战友，双方共同监督，共同进步，只要生活有了希望，背景差距倒显得不那么重要了。</p>
<h3 id="婚姻的四种状态"><a href="#婚姻的四种状态" class="headerlink" title="婚姻的四种状态"></a>婚姻的四种状态</h3><h4 id="郭沫若版（无爱无理解）"><a href="#郭沫若版（无爱无理解）" class="headerlink" title="郭沫若版（无爱无理解）"></a>郭沫若版（无爱无理解）</h4><p>​    号称文学大师的他，对婚姻其实更多的是反复和无耻的态度。其有三位妻子和一位情人，为了另寻新欢，打着“为革命牺牲”的名义，去摆脱这乏味的婚姻，以便他从头再来。大多数男生想和一个女生成为恋人，都是从性冲动开始的，就如猫儿见着鱼，狗儿见到骨头，不管鱼儿和骨头怎么样，每天见到，便难以克制。睡到更好，睡不着又不亏。无论男女，总有郭沫若这样人，荷尔蒙褪去之后,见到骨头，便忘了旧爱.如此以往，反反复复又来好几次，每次都是新希望，每次都惨淡收场。晚年郭沫若的妻子儿子都离开了他，他只能每日在家中抄写亡子日记以度日。</p>
<h4 id="老舍版（无爱有理解）"><a href="#老舍版（无爱有理解）" class="headerlink" title="老舍版（无爱有理解）"></a>老舍版（无爱有理解）</h4><p>​    老舍幼年家贫，上不起学，得以刘大善人的帮助，上了县城读书。从小便喜欢刘大善人的女儿，当他读书回来时，刘家家道中落，从小过惯了好日子的刘小姐为了维持好日子成为了暗娼。我曾试过去嫖娼，里面有大学女生，朋友圈还能见到她们穿毕业服装拍毕业照的视频。无爱，一切都是假的，伴随着卫生问题以及心理上的恶心，悻悻然而归。没有感情，不如自己动手丰衣足食。老舍曾写了很多文章来纪念这位初恋，后来三十几岁结婚，只是朋友的介绍，觉得互相不错，即相处了下来。这对他来说只是只是例行公事，所谓人都是要结婚的。当荷尔蒙褪去，老舍出轨了小他15岁的赵清阁，也正是因为赵清阁通过周总理的传话人，让老舍回到了国内，经历了文革十年。他能和老婆好好过日子，但在朋友林斤澜身边，说的最多的是“我家里的，什么也不懂”，在北京话里，称呼夫人为“我家里的”是非常不尊重的行为。后来，文革时期，揭发老舍的就是他妻子，还说什么死了就死了吧之类的话。向来也能理解，当老舍出轨后，她妻子是最后一个知道的，怨气与恨，可想而知。</p>
<h4 id="沈从文版（有爱无理解）"><a href="#沈从文版（有爱无理解）" class="headerlink" title="沈从文版（有爱无理解）"></a>沈从文版（有爱无理解）</h4><p>​    沈从文被胡适拉到上海当了老师，喜欢上了自己的女学生张兆和。从而展开了强烈的攻势，两人背景相差很大，而张兆和追求者众多，完全对他不感兴趣。在3年之后的纠缠中，他们两还是结婚了。只是感动始终不是爱情，张兆文始终无法理解沈从文的种种行为，婚后也对沈从文的很多事情不感兴趣，也许刚认识，激情还在的时候还能对他充满着好奇心，不过荷尔蒙大多数只能维持1年，之后就是平淡的岁月，平淡的日子，这时候就取决于两人是否能够互相理解，是否能够聊的来。婚姻除了睡觉和性爱，百分之80处于聊天的一个状态，聊得来很关键。而张兆文似乎与沈从文聊不到一块，甚至沈从文出轨，她也任然是一贯地平和淡然。沈从文很爱张兆文，不过他也无法忍受张兆文的态度，婚姻终究是这样平平淡淡偶尔有争吵的度过。当沈从文死去，他妻子整理遗稿中发现，体会了从文的心情、了解了他的处境、懂得了他的坚持与善良，常感叹:从文同我相处，这一辈子究竟是幸福还是不幸？并在其墓碑前刻下“不折不从，星斗其文。亦慈亦让，赤子其人”。想想来说也是个好名字，我因为是超生的，父母取名字单名个超字。也许以后我墓碑上也有人为我刻下“卓而不伍，超凡脱俗”来纪念我。</p>
<h4 id="钱钟书与杨绛（有爱有理解）"><a href="#钱钟书与杨绛（有爱有理解）" class="headerlink" title="钱钟书与杨绛（有爱有理解）"></a>钱钟书与杨绛（有爱有理解）</h4><p>​    感觉他们两给我的是一股正能量。他们在低谷，文革十年的时候，能为了对方与人揪头发扇耳光。很多事情处理的恰到好处。婚姻中有很多问题都靠双方无保留的交流化解了。我太羡慕，以致于我不想写，留与各位自己去看去听去感受。</p>
<h3 id="关于现代婚姻的感受"><a href="#关于现代婚姻的感受" class="headerlink" title="关于现代婚姻的感受"></a>关于现代婚姻的感受</h3><p>​    去打印简历的时候，发现打印室搜索的最多的是离婚协议格式，看来现代婚姻有很多地方不让人满意。忍一忍很快就一生就过去了，这得多受不了才能立马想着离婚。女人和男人都是一样的，男人惦记的是十几岁年轻活波的女性，其实几十岁的大妈也惦记着十几岁年轻小伙，只不过女人善于隐藏和撒谎，不像男人那么明显。男人和女人很多情况上都一样，但又存在着一点点的差异。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2019/01/04/spark2-0特性和rdd/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/04/spark2-0特性和rdd/" itemprop="url">spark2.0特性和rdd</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-04T15:28:53+08:00">
                2019-01-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>rdd、dataframe、dataset</p>
<p><img src="/2019/01/04/spark2-0特性和rdd/./spark2-0特性和rdd\spark数据载体及类型.png" alt="spark数据载体及类型"></p>
<p>### </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2019/01/04/avro序列化/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/04/avro序列化/" itemprop="url">avro序列化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-04T13:46:16+08:00">
                2019-01-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="为什么使用avro"><a href="#为什么使用avro" class="headerlink" title="为什么使用avro"></a>为什么使用avro</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> 最基本的格式是 CSV ，其廉价并且不需要顶一个一个 schema 和数据关联。</span><br><span class="line"></span><br><span class="line">随后流行起来的一个通用的格式是 XML，其有一个 schema 和 数据关联，XML 广泛的使用于 Web Services 和 SOA 架构中。不幸的是，其非常冗长，并且解析 XML 需要消耗内存。</span><br><span class="line"></span><br><span class="line">另外一种格式是 JSON，其非常流行易于使用因为它非常方便易于理解。</span><br><span class="line"></span><br><span class="line">这些格式在 Big Data 环境中都是不可拆分的，这使得他们难于使用。在他们之上使用一个压缩机制（Snappy，Gzip）并不能解决这个问题。</span><br><span class="line"></span><br><span class="line">因此不同的数据格式出现了。Avro 作为一种序列化平台被广泛使用，因为它能跨语言，提供了一个小巧紧凑的快速的二进制格式，支持动态 schema 发现（通过它的泛型）和 schema 演变，并且是可压缩和拆分的。它还提供了复杂的数据结构，例如嵌套类型。</span><br></pre></td></tr></table></figure>
<h3 id="avro序列化是什么"><a href="#avro序列化是什么" class="headerlink" title="avro序列化是什么"></a>avro序列化是什么</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">avro是hadoop的一个子项目，由hadoop的创始人牵头开发。其本身是一个数据序列化系统，其丰富的数据结构类型支持大批量数据交换的应用（shuffle阶段会有大量的rpc操作）。其本身支持二进制（或json）序列化。hadoop其本身进程间的通信依赖于java的<span class="type">DataOutputStream</span>和<span class="type">DataInputStream</span>（存在性能瓶颈），</span><br></pre></td></tr></table></figure>
<h3 id="avro定义数据格式"><a href="#avro定义数据格式" class="headerlink" title="avro定义数据格式"></a>avro定义数据格式</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">avro支持schema文件和idl配置文件定义数据格式。</span><br></pre></td></tr></table></figure>
<h3 id="avro依赖以及编译插件"><a href="#avro依赖以及编译插件" class="headerlink" title="avro依赖以及编译插件"></a>avro依赖以及编译插件</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;avro&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.8.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;avro-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.8.0&lt;/version&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;phase&gt;generate-sources&lt;/phase&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;goal&gt;schema&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;sourceDirectory&gt;$&#123;project.basedir&#125;/src/main/avro/&lt;/sourceDirectory&gt;</span><br><span class="line">                &lt;outputDirectory&gt;$&#123;project.basedir&#125;/src/main/java/&lt;/outputDirectory&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;source&gt;1.8&lt;/source&gt;</span><br><span class="line">        &lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">        <span class="comment">//如果是jdk版本问题请改为1.6</span></span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure>
<h4 id="创建avro文件夹"><a href="#创建avro文件夹" class="headerlink" title="创建avro文件夹"></a>创建avro文件夹</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在main包下创建avro文件夹。</span><br></pre></td></tr></table></figure>
<h4 id="idl配置文件"><a href="#idl配置文件" class="headerlink" title="idl配置文件"></a>idl配置文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">@namespace(&quot;com.wuchao.avro&quot;)</span><br><span class="line">ptotocol logProtocol&#123;</span><br><span class="line">    record Client&#123;</span><br><span class="line">    //字段不为null时不能使用union</span><br><span class="line">        union&#123;null,String&#125; clientType;</span><br><span class="line">    &#125;</span><br><span class="line">    record UserInfo&#123;</span><br><span class="line">	//字段有默认值</span><br><span class="line">       @default(&quot;wuchao&quot;) String username;</span><br><span class="line">    //字段需要使用decimal</span><br><span class="line">       @java-class(&quot;java.math.BigDecimal&quot;) union&#123;null,string&#125; price</span><br><span class="line">    &#125;</span><br><span class="line">    enum EventType&#123;</span><br><span class="line">        UserInfo,</span><br><span class="line">        Client</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="scheme配置文件"><a href="#scheme配置文件" class="headerlink" title="scheme配置文件"></a>scheme配置文件</h4><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;"namespace": "com.wuchao.avro",</span><br><span class="line"> "type": "record",</span><br><span class="line"> "name": "User",</span><br><span class="line"> "fields": [</span><br><span class="line">     &#123;"name": "name", "type": "string"&#125;,</span><br><span class="line">     &#123;"name": "favorite_number",  "type": ["int", "null"]&#125;,</span><br><span class="line">     &#123;"name": "favorite_color", "type": ["string", "null"]&#125;</span><br><span class="line"> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="生成对应的java文件"><a href="#生成对应的java文件" class="headerlink" title="生成对应的java文件"></a>生成对应的java文件</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">idl转scheme:</span><br><span class="line">java -jar avro-tools<span class="number">-1.8</span><span class="number">.2</span>.jar idl2schemata $input<span class="comment">//输入参数</span></span><br><span class="line">scheme生成：</span><br><span class="line">java -jar /path/to/avro-tools<span class="number">-1.8</span><span class="number">.0</span>.jar compile schema &lt;schema file&gt; &lt;destination&gt;</span><br><span class="line"><span class="comment">//借助工具包  avro-tools-1.8.2.jar</span></span><br><span class="line">上面的maven编译插件也能做到scheme生成java这一步：</span><br><span class="line"> &lt;sourceDirectory&gt;$&#123;project.basedir&#125;/src/main/avro/&lt;/sourceDirectory&gt;</span><br><span class="line"> &lt;outputDirectory&gt;$&#123;project.basedir&#125;/src/main/java/&lt;/outputDirectory&gt;</span><br></pre></td></tr></table></figure>
<h4 id="mr-avro序列化"><a href="#mr-avro序列化" class="headerlink" title="mr avro序列化"></a>mr avro序列化</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop创始人代码：</span><br><span class="line">https:<span class="comment">//bit1129.iteye.com/blog/2200376</span></span><br></pre></td></tr></table></figure>
<h4 id="spark-scala-处理avro（生成avro也可以，不过不想花时间在上面了）"><a href="#spark-scala-处理avro（生成avro也可以，不过不想花时间在上面了）" class="headerlink" title="spark scala  处理avro（生成avro也可以，不过不想花时间在上面了）"></a>spark scala  处理avro（生成avro也可以，不过不想花时间在上面了）</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">avro scheme:</span><br><span class="line">&#123;</span><br><span class="line">   <span class="string">"type"</span> : <span class="string">"record"</span>,</span><br><span class="line">   <span class="string">"name"</span> : <span class="string">"twitter_schema"</span>,</span><br><span class="line">   <span class="string">"namespace"</span> : <span class="string">"com.miguno.avro"</span>,</span><br><span class="line">   <span class="string">"fields"</span> : [</span><br><span class="line">        &#123;     <span class="string">"name"</span> : <span class="string">"username"</span>,</span><br><span class="line">               <span class="string">"type"</span> : <span class="string">"string"</span>,</span><br><span class="line">              <span class="string">"doc"</span>  : <span class="string">"Name of the user account on Twitter.com"</span>   &#125;,</span><br><span class="line">         &#123;</span><br><span class="line">             <span class="string">"name"</span> : <span class="string">"tweet"</span>,</span><br><span class="line">             <span class="string">"type"</span> : <span class="string">"string"</span>,</span><br><span class="line">             <span class="string">"doc"</span>  : <span class="string">"The content of the user‘s Twitter message"</span>   &#125;,</span><br><span class="line">         &#123;</span><br><span class="line">             <span class="string">"name"</span> : <span class="string">"timestamp"</span>,</span><br><span class="line">             <span class="string">"type"</span> : <span class="string">"long"</span>,</span><br><span class="line">             <span class="string">"doc"</span>  : <span class="string">"Unix epoch time in seconds"</span>   &#125; </span><br><span class="line">    ],</span><br><span class="line">   <span class="string">"doc:"</span> : <span class="string">"A basic schema for storing Twitter messages"</span> </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">twitter.json中数据：</span><br><span class="line">&#123;<span class="string">"username"</span>:<span class="string">"miguno"</span>,<span class="string">"tweet"</span>:<span class="string">"Rock: Nerf paper, scissors is fine."</span>,<span class="string">"timestamp"</span>: <span class="number">1366150681</span> &#125; </span><br><span class="line">&#123;<span class="string">"username"</span>:<span class="string">"BlizzardCS"</span>,<span class="string">"tweet"</span>:<span class="string">"Works as intended.  Terran is IMBA."</span>,<span class="string">"timestamp"</span>: <span class="number">1366154481</span> &#125;</span><br><span class="line"></span><br><span class="line">转换成avro文件</span><br><span class="line">java -jar ~/avro-tools-<span class="number">1.8</span>.2.jar fromjson --schema-file twitter.avsc twitter.json &gt; twitter.avro</span><br><span class="line"></span><br><span class="line">生成java:</span><br><span class="line">$ java -jar /app/avro/avro-tools-<span class="number">1.8</span>.2.jar compile schema /app/avro/data/twitter.avsc /app/avro/data/</span><br><span class="line"></span><br><span class="line">编译java类并打包：</span><br><span class="line">$ CLASSPATH=/app/avro/avro-<span class="number">1.8</span>.2-javadoc.jar:/app/avro/avro-mapred-<span class="number">1.8</span>.2-hadoop1.jar:/app/avro/avro-tools-<span class="number">1.8</span>.2.jar</span><br><span class="line">$ javac -classpath $CLASSPATH /app/avro/data/com/miguno/avro/twitter_schema.java</span><br><span class="line">$ jar cvf Twitter.jar com/miguno/avro<span class="comment">/*.class</span></span><br></pre></td></tr></table></figure>
<h4 id="处理avro数据："><a href="#处理avro数据：" class="headerlink" title="处理avro数据："></a>处理avro数据：</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> path = <span class="string">"/app/avro/data/twitter.avro"</span></span><br><span class="line"><span class="keyword">val</span> avroRDD = sc.hadoopFile[<span class="type">AvroWrapper</span>[<span class="type">GenericRecord</span>], <span class="type">NullWritable</span>, <span class="type">AvroInputFormat</span>[<span class="type">GenericRecord</span>]](path)</span><br><span class="line"><span class="comment">//获取第一个数据</span></span><br><span class="line">avroRDD.map(l =&gt; <span class="keyword">new</span> <span class="type">String</span>(l._1.datum.get(<span class="string">"username"</span>).toString() ) ).first</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2018/11/19/jvm详解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/19/jvm详解/" itemprop="url">jvm详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-19T09:20:13+08:00">
                2018-11-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2018/11/17/flink真正简单入门/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/17/flink真正简单入门/" itemprop="url">flink真正简单入门</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-17T16:52:49+08:00">
                2018-11-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    前面写了很多东西，其实都是在计流水账，写的虽然说是入门教程，但相信各位也看出来很多知识点错综复杂，毫无逻辑点可言。由于博主当时也赶时间，写的有点匆忙，今天补一篇真正的flink入门教程。</p>
<h3 id="flink的优势"><a href="#flink的优势" class="headerlink" title="flink的优势"></a>flink的优势</h3><p>​    自从数据量超过了传统数据库能有效处理的数据量之后，Hadoop等各种基础mapreduce的海量数据处理系统应运而生。大数据架构一般分为存储和计算。存储在hdfs上进行。而计算又分为实时计算和离线计算。离线并行计算框架有mapreduce，实时并行计算框架有storm、spark、flink。</p>
<p>​    storm的流式计算，因为其保证数据接收的机制（at most  once和at least once），在处理大量数据时，会不可避免地产生数据丢失和数据重复。当其ack机制（消息确认机制）置1时，能大概率的保证数据的有效性，却不可避免的影响处理数据的效率。spark streaming的流式计算，数据丢失上的问题spark streaming能够有效避免，但是spark streaming的流其实是微批计算，将数据分割成尽可能小的批次处理，不能算的上实时的流计算，实时性并不是很高。flink可以说是当今集高效、容错、实时与一体的并行计算框架。</p>
<h3 id="flink的安装和简单例子"><a href="#flink的安装和简单例子" class="headerlink" title="flink的安装和简单例子"></a>flink的安装和简单例子</h3><p><img src="/2018/11/17/flink真正简单入门/flink安装版本.png" alt="flink安装版本"></p>
<p>​    博主是cdh hadoop2.6与flink开始整合的。由于电脑配置太低，只启了两台虚拟机。</p>
<p>​    两台主机同时执行mkdir -p softwares/</p>
<p>​    将flink压缩包上传至第一台虚拟机该目录下</p>
<p>​    </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cd /softwares/flink/conf</span><br><span class="line">vim flink-conf.yaml  //yaml格式极为严格 多个空格或是少个空格有时都不行</span><br><span class="line">修改主节点jobmanager地址：</span><br><span class="line">jobmanager.rpc.address： your ipadress</span><br><span class="line">vim slave </span><br><span class="line">将副节点的ip放在该文件下</span><br><span class="line">scp -r flink 第二台虚拟机ip:$PWD</span><br><span class="line">在主节点启动：</span><br><span class="line">bin/start-cluster.sh</span><br><span class="line">jps(查看java相关进程)</span><br><span class="line">副节点上执行：</span><br><span class="line">nc -l 9000 (产生消息) 输入</span><br><span class="line">在副节点提交example的例子：</span><br><span class="line">bin/flink run  examples/streaming/SocketWindowWordCount.jar --port 9000  （监听9000）</span><br><span class="line">查看flink控制面板：第一台虚拟机ip:8081</span><br></pre></td></tr></table></figure>
<p>​    效果如下：<img src="/2018/11/17/flink真正简单入门/flink控制面板.png" alt="flink控制面板"></p>
<p><img src="/2018/11/17/flink真正简单入门/flink执行流式任务.png" alt="flink执行流式任务"></p>
<p>cd /softwares/flink/log</p>
<p>查看输出日志和运行日志</p>
<p><img src="/2018/11/17/flink真正简单入门/E:/blog\source\_posts\flink真正简单入门\运行日志和输出日志.png" alt="运行日志和输出日志"></p>
<p>tail -f 输出日志文件名</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2018/11/14/大数据面试知识点/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/14/大数据面试知识点/" itemprop="url">大数据面试知识点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-14T09:03:42+08:00">
                2018-11-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h3><p>随着时代技术的发展，数据量在不断的增大。《大数据时代》中大数据不能再用随机分析（抽样调查）的方法来处理数据。</p>
<h3 id="mapreduce过程"><a href="#mapreduce过程" class="headerlink" title="mapreduce过程"></a>mapreduce过程</h3><p>1.读取hdfs中的文件。每一行解析成一个&lt;k,v&gt; 1 (偏移量，输入的值)1</p>
<p>2.重写map(),生成新的&lt;k,v&gt; 2</p>
<p>3.partition 分区 默认分为一个区 可以重写分区 按key分区</p>
<p>4.排序  （自定义排序类）</p>
<p>5.对分组排序后的数据进行规约，其实就是进行一次小合并，减少数据传输量 （比如说累加或是求topN就是在这进行的）</p>
<p>6.shuffle:</p>
<p>map端shuffle：多个inputSplit获取到自己的mapTask,map任务结束后产生k2,每个map有个环形内存缓冲区，默认大小100M,溢写比为0.8，达到阈值后将文件写道磁盘中。缓存的好处减少IO开销，提高合并排序速度。在编写map时少使用内存，尽量给shuffle过程预留时间，这个阶段最耗费时间。</p>
<p>reduce阶段：通过http方式得到文本，每个map的结束时间不一致。datanode可以通过namenode获取其信息。如果形成多个磁盘文件会进行合并最后一次合并结果作为reduce的输入而不是写到磁盘。</p>
<p>7.对多个map进行合并，相同key的reduce发送到一起，产生新的&lt;k,v&gt; 3</p>
<p>8将输出输出到hdfs</p>
<h3 id="spark-streaming过程"><a href="#spark-streaming过程" class="headerlink" title="spark streaming过程"></a>spark streaming过程</h3><p>spark程序是使用一个spark应用实例一次性对一批历史数据进行处理，spark streaming是将持续不断输入的数据流转换成多个batch分片，使用一批spark应用实例进行处理。 </p>
<ol>
<li>一个静态的 RDD DAG 的模板，来表示处理逻辑；</li>
<li>一个动态的工作控制器，将连续的 streaming data 切分数据片段，并按照模板复制出新的 RDD ；</li>
<li>DAG 的实例，对数据片段进行处理；</li>
<li>Receiver进行原始数据的产生和导入；Receiver将接收到的数据合并为数据块并存到内存或硬盘中，供后续batch RDD进行消费；</li>
<li>对长时运行任务的保障，包括输入数据的失效后的重构，处理任务的失败后的重调。</li>
</ol>
<p>Executor以线程的方式执行每一个task。</p>
<p>DAG调度的过程中，根据shuffle划分stage</p>
<p>未优化的shuffle阶段，shuffleMapTask和reduceTask中会产生大量的block file </p>
<p>hashshuffle</p>
<p>优化后：根据cpu核心数决定Task的并发数量，根据reduceTask创建bucket,bucket决定block file的数量，问题是reduceTask很大怎么办？相当于bucket是聚合了mapTask和reduceTask<br>Sorted-Based Shuffle</p>
<p>为了缓解Shuffle过程产生文件数过多和Writer缓存开销过大的问题，spark引入了类似于hadoop Map-Reduce的shuffle机制。该机制每一个ShuffleMapTask不会为后续的任务创建单独的文件，而是会将所有的Task结果写入同一个文件，并且对应生成一个索引文件。以前的数据是放在内存缓存中，等到数据完了再刷到磁盘，现在为了减少内存的使用，在内存不够用的时候，可以将输出溢写到磁盘，结束的时候，再将这些不同的文件联合内存的数据一起进行归并，从而减少内存的使用量。一方面文件数量显著减少，另一方面减少Writer缓存所占用的内存大小，而且同时避免GC的风险和频率。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2018/11/13/spark简单入门/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/13/spark简单入门/" itemprop="url">spark简单入门</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-13T10:26:12+08:00">
                2018-11-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Spark、Storm、Mapreduce、flink的区别"><a href="#Spark、Storm、Mapreduce、flink的区别" class="headerlink" title="Spark、Storm、Mapreduce、flink的区别"></a>Spark、Storm、Mapreduce、flink的区别</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">并行计算：分布式系统中有多个cpu参与计算。任何号称多任务处理的操作系统，在一个cpu一个核心的情况下，只能在同一时间处理一个线程，串行执行任务。记得在北航麦中凡教授写的书中有一句话使我印象深刻，计算机的本质是快能补拙，无论是机器学习还是什么其他技术，都能感觉到计算机的笨拙。很多人眼一眼看出来的排序，计算机也得经过无数的指令。</span><br><span class="line"></span><br><span class="line">流：计算机中的各种设备（鼠标，键盘）之间的数据传递都是以流的形式传递的，计算机底层的数据流经过封装（在交换机中）成为一帧一帧的数据：数据帧，在交换机中把ip地址和目的地址封装号之后封装成数据包发到公网。</span><br><span class="line"></span><br><span class="line">mapreduce是最早的并行计算框架（非内存计算），启动任务需要的时间和资源都是最多的，而且编写相对来说复杂，适合处理离线任务。storm流式计算，通过tuple封装数据，bolt传输数据，采用ack机制确保数据不丢失，ack为<span class="number">0</span>只需要确认数据发出，不需要等到bolt的确认消息，而置<span class="number">1</span>的时候需要确认。因为采取的数据传输方式为at most once和at least once 容易导致数据丢失和数据重复。spark其实是微批式的计算框架，并不能算做为真正的实时计算，采取的exactly once和checkpoint（发生错误是执行回滚操作）保证数据的不丢失不重复，实时性低下。flink是真正的流式内存计算框架，以上所说的优点全占，缺点不沾边。目前flink在现在已经在很多一线互联网公司处于试水阶段，阿里算是试水比较早的，在<span class="number">2017</span>年已经开始应用了。</span><br></pre></td></tr></table></figure>
<h3 id="Spark数据载体RDD-弹性分布式数据集"><a href="#Spark数据载体RDD-弹性分布式数据集" class="headerlink" title="Spark数据载体RDD(弹性分布式数据集)"></a>Spark数据载体RDD(弹性分布式数据集)</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span><span class="type">RDD</span>存放于内存中，以分区为计算单位，如果创建的时候没有指定分区数，采取默认值</span><br><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="keyword">val</span> rdd2 = sc.textFile(<span class="string">"/word.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> rdd3 = rdd2.flatMap(_.split(<span class="string">" "</span>)) </span><br><span class="line"><span class="number">2.</span>rdd的算子操作（transformation，action）</span><br><span class="line">- transformation:根据操作生成一个新的rdd，数据的预处理，并不会真正执行</span><br><span class="line">- action:把计算结果提交给驱动，或是提交给hdfs,数据的真正执行</span><br><span class="line"><span class="number">3.</span>宽依赖和窄依赖</span><br><span class="line">窄依赖：父rdd里的一个分区至多被一个子rdd里面的分区使用</span><br><span class="line">宽依赖：父rdd的一个分区可以被子rdd里的多个分区使用</span><br><span class="line"><span class="number">4.</span>血统（lineage）</span><br><span class="line">记录父<span class="type">RDD</span>的操作，方便数据恢复（数据恢复先从血统里找，设置了还原点checkpoint，再从checkpoint中回滚）</span><br><span class="line">设置缓存缓存某一阶段的数据：persist和cache的区别：</span><br><span class="line">一个默认了存储级别，一个可以自定义存储级别（storerageLevel）</span><br><span class="line"><span class="type">DagScheduler</span>:(有向无环图调度器)</span><br><span class="line">如果每个<span class="type">RDD</span>的操作都需要缓存一下的话，需要的内存太大了，通过dag划分可以把重要的结果缓存下来，划分也极为简单，遇到宽依赖就划分。</span><br><span class="line"><span class="type">TaskScheduler</span>(任务调度器):真正的执行者</span><br><span class="line">dag会把任务划为一组一组的taskSet任务集，taskScheduler将任务提交到集群运行。</span><br></pre></td></tr></table></figure>
<p><img src="/2018/11/13/spark简单入门/spark任务调度.png" alt="spark任务调度"></p>
<h3 id="SparkSql"><a href="#SparkSql" class="headerlink" title="SparkSql"></a>SparkSql</h3><p>DataFrame :提供了类似表的结构数据，与RDD不同是IO开销增大，失去了类型安全的机制。可以转换</p>
<p>为dataset恢复RDD的特性进行数据传输。</p>
<p>通过df.registerTemptable(“person”) 将df的数据注册成为一张表</p>
<p>spark.sql(“select * from person”).show  来在spark shell 中查询</p>
<h3 id="SparkSql操作hive（未整合）："><a href="#SparkSql操作hive（未整合）：" class="headerlink" title="SparkSql操作hive（未整合）："></a>SparkSql操作hive（未整合）：</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HiveSupport</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="comment">//todo:1、创建sparkSession</span></span><br><span class="line">     <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">       .appName(<span class="string">"HiveSupport"</span>)</span><br><span class="line">       .master(<span class="string">"local[2]"</span>)</span><br><span class="line">       .config(<span class="string">"spark.sql.warehouse.dir"</span>, <span class="string">"d:\\spark-warehouse"</span>)</span><br><span class="line">       .enableHiveSupport() <span class="comment">//开启支持hive</span></span><br><span class="line">       .getOrCreate()</span><br><span class="line">    spark.sparkContext.setLogLevel(<span class="string">"WARN"</span>)  <span class="comment">//设置日志输出级别</span></span><br><span class="line"><span class="comment">//倘若jvm中内存不足的话，可以在edit configuration中有关虚拟机内存的地方设置</span></span><br><span class="line"><span class="comment">//-Xms512m -Xmx1024m</span></span><br><span class="line"></span><br><span class="line">    spark.sql(<span class="string">"CREATE TABLE IF NOT EXISTS person (id int, name string, age int) row format delimited fields terminated by ' '"</span>)</span><br><span class="line">    spark.sql(<span class="string">"LOAD DATA LOCAL INPATH './data/student.txt' INTO TABLE person"</span>)</span><br><span class="line">    spark.sql(<span class="string">"select * from person "</span>).show()</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="SparkSql整合hive"><a href="#SparkSql整合hive" class="headerlink" title="SparkSql整合hive"></a>SparkSql整合hive</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Spark真正和hive的整合 将hive的mr作业换成了spark作业 spark on hive</span></span><br><span class="line"><span class="comment">//hive on spark 将mr计算引擎换成spark streaming计算引擎</span></span><br><span class="line">--需要启动 hive --service metastore &amp;</span><br></pre></td></tr></table></figure>
<h3 id="SparkStreaming"><a href="#SparkStreaming" class="headerlink" title="SparkStreaming"></a>SparkStreaming</h3><p>Spark Streaming 是基于spark的流式批处理引擎，其基本原理是把输入数据以某一时间间隔批量的处理，当批处理间隔缩短到秒级时，便可以用于处理实时数据流。</p>
<p>通过这段介绍我们就可以知道spark streaming计算引擎根本不是实时性非常高的计算引擎,只是一个微批次计算的引擎。</p>
<h3 id="Dstream"><a href="#Dstream" class="headerlink" title="Dstream"></a>Dstream</h3><p>Dstream作为spark streaming 的数据载体，是由一串不同时间的连续的RDD构成的。</p>
<p>窗口滑动操作：每隔一段时间计算一次当前批次的结果。</p>
<h3 id="Kafka整合Spark"><a href="#Kafka整合Spark" class="headerlink" title="Kafka整合Spark"></a>Kafka整合Spark</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreamingKafka_Direct</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="comment">//1、创建sparkConf</span></span><br><span class="line">      <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">        .setAppName(<span class="string">"SparkStreamingKafka_Direct"</span>)</span><br><span class="line">        .setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line">      <span class="comment">//2、创建sparkContext</span></span><br><span class="line">      <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line">      sc.setLogLevel(<span class="string">"WARN"</span>)</span><br><span class="line">      <span class="comment">//3、创建StreamingContext</span></span><br><span class="line">      <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc,<span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line">ssc.checkpoint(<span class="string">"./Kafka_Direct"</span>)</span><br><span class="line">      <span class="comment">//4、配置kafka相关参数</span></span><br><span class="line">      <span class="keyword">val</span> kafkaParams=<span class="type">Map</span>(<span class="string">"metadata.broker.list"</span>-&gt;<span class="string">"node1:9092,node2:9092,node3:9092"</span>,<span class="string">"group.id"</span>-&gt;<span class="string">"Kafka_Direct"</span>)</span><br><span class="line">      <span class="comment">//5、定义topic</span></span><br><span class="line">      <span class="keyword">val</span> topics=<span class="type">Set</span>(<span class="string">"spark01"</span>)</span><br><span class="line">      <span class="comment">//6、通过 KafkaUtils.createDirectStream接受kafka数据，这里采用是kafka低级api偏移量不受zk管理</span></span><br><span class="line">      <span class="keyword">val</span> dstream: <span class="type">InputDStream</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>,<span class="type">String</span>,<span class="type">StringDecoder</span>,<span class="type">StringDecoder</span>](ssc,kafkaParams,topics)</span><br><span class="line">      <span class="comment">//7、获取kafka中topic中的数据</span></span><br><span class="line">        <span class="keyword">val</span> topicData: <span class="type">DStream</span>[<span class="type">String</span>] = dstream.map(_._2)</span><br><span class="line">      <span class="comment">//8、切分每一行,每个单词计为1</span></span><br><span class="line">      <span class="keyword">val</span> wordAndOne: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = topicData.flatMap(_.split(<span class="string">" "</span>)).map((_,<span class="number">1</span>))</span><br><span class="line">      <span class="comment">//9、相同单词出现的次数累加</span></span><br><span class="line">      <span class="keyword">val</span> result: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordAndOne.reduceByKey(_+_)</span><br><span class="line">        <span class="comment">//wordAndOne.reduceByKeyAndWindow((a:Int,b:Int)=&gt;a+b,Seconds(10),Seconds(5))</span></span><br><span class="line">        <span class="comment">//利用开窗函数统计   窗口滑动应该为批次时间的整数倍，窗口长度应该为窗口滑动的整数倍</span></span><br><span class="line">      <span class="comment">//10、打印输出</span></span><br><span class="line">      result.print()</span><br><span class="line">      <span class="comment">//开启计算</span></span><br><span class="line">      ssc.start()</span><br><span class="line">      ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2018/11/07/hive/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/07/hive/" itemprop="url">hive</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-07T08:32:59+08:00">
                2018-11-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="hive是什么"><a href="#hive是什么" class="headerlink" title="hive是什么"></a>hive是什么</h3><p>​    </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive是基于<span class="type">Hadoop</span>的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，</span><br><span class="line">并提供简单的sql查询功能，可以将sql语句转换为<span class="type">MapReduce</span>任务进行运行。 </span><br><span class="line">hive其实就是一个实时在线的分析平台（<span class="type">OLAP</span>）的查询工具,与mysql的区别在于：</span><br><span class="line">hive的数据存储在hdfs，查询延迟低，适合大批量 数据的处理。hadoop生态圈中，</span><br><span class="line">hdfs用于存储数据，mapreduce用于分析数据，hive则是内置了mapreduce的一个查询工具。</span><br><span class="line">很多新技术入门其实不难，不要认为一个新技术就怎么高大上了，历史告诉我们只有少数人创新</span><br><span class="line">大部分跟着重复造轮子，跟着前人脚步走，这还不简单么。</span><br></pre></td></tr></table></figure>
<h3 id="数据仓库分层架构"><a href="#数据仓库分层架构" class="headerlink" title="数据仓库分层架构"></a>数据仓库分层架构</h3><p><img src="/2018/11/07/hive/数据仓库架构.png" alt="数据仓库架构"></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">贴源层：源数据的抽取与转换在这里进行</span><br><span class="line"></span><br><span class="line">数据仓库层：hive工作的地方，数据的清洗在这里进行</span><br><span class="line"></span><br><span class="line">数据应用：生成页面展示数据</span><br><span class="line"></span><br><span class="line">不管是网络模型还是框架都有明确的分层机制：好处是减少耦合性，分工明确，</span><br><span class="line">使繁琐的业务简单化，产生错误也能尽快定位错误位置，易扩展</span><br></pre></td></tr></table></figure>
<h3 id="hive的数据表"><a href="#hive的数据表" class="headerlink" title="hive的数据表"></a>hive的数据表</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hive的数据表是一个映射表，所谓映射，来自于数学方面中的影射或映射，指两个元素存在相应的关系。例如一对一、一对多、多对一。hive表映射的是hdfs中</span><br><span class="line">hive的元数据（表的结构、映射、权限等信息）存储在mysql/derby中，表数据存在hdfs中</span><br><span class="line">管理表:内部表</span><br><span class="line">外部表：create external table techer (t_id string,t_name string) row format delimited fields terminated by '\t' location '/scoredatas'</span><br><span class="line">数据来源：数据来自于hdfs的外部加载。可指定hive中表数据在hdfs存储的位置</span><br><span class="line">分区表：分区指定的字段其实会加入表中，按该字段分文件夹存储</span><br><span class="line">分区表把文件分为不同时间，查看指定分区表数据位置describe formatted table_name partition(<span class="string">"month"</span>)</span><br><span class="line">create table score(s_id string,c_id string, s_score int) partitioned by (month string) row format delimited fields terminated by '\t';  <span class="comment">//partition (month='201806')加载数据得指定分区</span></span><br><span class="line">分桶表：具有排序的功能，根据hash算法分成不同的小文件</span><br><span class="line">create table course (c_id string,c_name string,t_id string) clustered by(c_id) into <span class="number">3</span> buckets row format delimited fields terminated by '\t';</span><br><span class="line">分桶表加载数据只能用overwrite:</span><br><span class="line">insert overwrite table course select * from course_common cluster by(c_id);</span><br></pre></td></tr></table></figure>
<h3 id="hive的导入导出"><a href="#hive的导入导出" class="headerlink" title="hive的导入导出"></a>hive的导入导出</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive从本地加载并覆盖数据：</span><br><span class="line">load data local inpath '/export/servers/hivedatas/student.csv' overwrite  into table student;</span><br><span class="line">从hdfs加载数据：</span><br><span class="line">load data inpath '/hivedatas/techer.csv' into table techer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive导出到本地：</span><br><span class="line">insert overwrite local directory '/export/servers/exporthive' select * from score;</span><br><span class="line">结构化数据导出到本地：</span><br><span class="line">insert overwrite local directory '/export/servers/exporthive' row format delimited fields terminated by '\t' collection items terminated by '#' select * from student;</span><br><span class="line">hive shell导出到本地：</span><br><span class="line">bin/hive -e <span class="string">"select * from myhive.score;"</span> &gt; /export/servers/exporthive/score.txt</span><br><span class="line">hdfs导出hive表文件到本地：</span><br><span class="line">dfs -get /export/servers/exporthive/<span class="number">000000</span>_0 /export/servers/exporthive/local.txt;</span><br><span class="line">导出到hdfs:</span><br><span class="line">insert overwrite directory '/export/servers/exporthive' row format delimited fields terminated by '\t' collection items terminated by '#' select * from score;</span><br><span class="line">export导出到hdfs:</span><br><span class="line">export table score to '/export/exporthive/score';</span><br><span class="line"><span class="comment">//set mapreduce.job.reduces=3</span></span><br><span class="line"><span class="comment">//查询结果导入本地insert overwrite local directory '/export/servers/hivedatas/sort' select * from score sort by s_score;</span></span><br><span class="line"><span class="comment">//分布式并行计算框架mapreduce需要多次网络传输，采取压缩方式能减少传输数据量</span></span><br><span class="line"><span class="comment">//开启map中间输出压缩set hive.exec.compress.intermediate=true</span></span><br><span class="line"><span class="comment">//开启map输出压缩mapreduce.map.output.compress=true;</span></span><br><span class="line"><span class="comment">//设置压缩方式（还有reduce和最终输出压缩这里就不写了）set mapreduce.map.output.compress.codec= org.apache.hadoop.io.compress.SnappyCodec</span></span><br></pre></td></tr></table></figure>
<h3 id="hive的存储格式"><a href="#hive的存储格式" class="headerlink" title="hive的存储格式"></a>hive的存储格式</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Text</span>，<span class="type">SequenceFile</span>，<span class="type">ParquetFile</span>（二进制存储），<span class="type">ORC</span>（相当于数据包，把数据封装）</span><br><span class="line"><span class="comment">//后两种为列式存储  行式存储要读完自己部分的数据务必要读到其他不相干的数据</span></span><br></pre></td></tr></table></figure>
<h3 id="hive的优化"><a href="#hive的优化" class="headerlink" title="hive的优化"></a>hive的优化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1.Fetch抓取(避免mapreduce),也可以开启本地模式的mapreduce,单进程，一个人mr任务组</span><br><span class="line">2.表优化（多表联查加载顺序从左至右，尽量把大表放在后面加载。减少网络传输）</span><br><span class="line">3.数据倾斜:数据在mapreduce中分布不均。</span><br><span class="line">小文件合并，减少map</span><br><span class="line">单个文件数据量大，增加map</span><br><span class="line">调整reduce数</span><br><span class="line">4.设置并行执行</span><br><span class="line">set hive.exec.parallel=true;              </span><br><span class="line">set hive.exec.parallel.thread.number=16;</span><br><span class="line">5.严格模式</span><br><span class="line">防止好人干坏事</span><br><span class="line">6.jvm重用</span><br><span class="line">jvm的子类实例</span><br><span class="line">7.推测执行</span><br><span class="line">给出一个任务的替代方案，运行情况优则替换</span><br><span class="line">8.压缩</span><br><span class="line">减少网络传输</span><br></pre></td></tr></table></figure>
<h3 id="hive函数"><a href="#hive函数" class="headerlink" title="hive函数"></a>hive函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">concat_ws 拼接多行为一行，以某元素为分隔符</span><br><span class="line">select split(concat_ws(&apos;,&apos;,&apos;1&apos;,&apos;2&apos;,&apos;3&apos;,&apos;4&apos;,&apos;5&apos;,&apos;6&apos;,&apos;7&apos;,&apos;8&apos;,&apos;9&apos;),&apos;,&apos;)  sp</span><br><span class="line">from test.dual; </span><br><span class="line">select s.*,spfrom test.dual slateral view explode(split(concat_ws(&apos;,&apos;,&apos;1&apos;,&apos;2&apos;,&apos;3&apos;,&apos;4&apos;,&apos;5&apos;,&apos;6&apos;,&apos;7&apos;,&apos;8&apos;,&apos;9&apos;),&apos;,&apos;)) t as sp;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2018/11/03/sql语句/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/03/sql语句/" itemprop="url">sql语句</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-03T15:16:39+08:00">
                2018-11-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​            </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//结构化数据：那些按照一定规律和顺序排列的数据的数据，通常指数据库 本来晚上想写一下hive的 </span></span><br><span class="line"><span class="comment">//没想到今天把昨天的代码敲了两遍，还是提前敲完了，还是先写一下sql吧。</span></span><br><span class="line"><span class="comment">//数据库备份 mysqldump -u用户名 -p密码 数据库名&gt;导出文件路径   </span></span><br><span class="line"><span class="comment">//数据库还是多备份点，要是真删库了，能跑多远跑多远</span></span><br></pre></td></tr></table></figure>
<h3 id="DML、DDL、DCL"><a href="#DML、DDL、DCL" class="headerlink" title="DML、DDL、DCL"></a>DML、DDL、DCL</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">DML:<span class="function">database manager <span class="title">language</span><span class="params">(三种对数据库事务性的操作:增删改表记录)</span></span></span><br><span class="line"><span class="function">- 1.insert insert into <span class="title">table_name</span><span class="params">(列名，列名)</span> <span class="title">values</span> <span class="params">(列值，列值)</span></span></span><br><span class="line"><span class="function">- 2.update update table_name set 列名</span>=列值（，列名=列值） where (条件判断)</span><br><span class="line">- <span class="number">3</span>.<span class="function">delete delete from table_name <span class="title">where</span> <span class="params">(条件判断)</span></span></span><br><span class="line"><span class="function">DDL：database define <span class="title">language</span><span class="params">(对数据库、表增删改的操作)</span>DML是对表数据的操作</span></span><br><span class="line"><span class="function">创建库表</span></span><br><span class="line"><span class="function">- 1.create table <span class="title">table_name</span><span class="params">(name varchar(<span class="number">10</span>)</span>,age <span class="keyword">int</span>)</span></span><br><span class="line"><span class="function">- 2.create database database_name </span></span><br><span class="line"><span class="function">删除库表</span></span><br><span class="line"><span class="function">- 1.drop database database_name</span></span><br><span class="line"><span class="function">- 2.drop table_name</span></span><br><span class="line"><span class="function">更改库表</span></span><br><span class="line"><span class="function">- 1.alter database database_name charset set <span class="title">utf8</span><span class="params">(改数据库编码)</span></span></span><br><span class="line"><span class="function">- 2.alter table table_name <span class="title">add</span> <span class="params">(列名 列类型)</span>/drop 列名（增删列）</span></span><br><span class="line"><span class="function">DCL：database controller <span class="title">language</span> <span class="params">(数据库控制语言：创建用户、给用户授权或撤销权限)</span></span></span><br><span class="line"><span class="function">- 1.grant all on database_name.* to 用户名@<span class="title">ip</span><span class="params">(all:授予所有权限)</span></span></span><br><span class="line"><span class="function">- 2.revoke create,delete on database_name.* from 用户名@ip 撤销用户的create、delete权限</span></span><br><span class="line"><span class="function">- 3.create user 用户名@"%" identified by '密码'	（创建用户，%代表任意ip地址）</span></span><br></pre></td></tr></table></figure>
<h3 id="DQL"><a href="#DQL" class="headerlink" title="DQL"></a>DQL</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//说实在话 布置的那100道题目是我第二次这么长时间写sql </span></span><br><span class="line"><span class="comment">//感觉sql并不难，关键是得静下心来一步一步分析下来，从会做的开始做，剩下的慢慢都能做的来</span></span><br><span class="line">- <span class="number">1</span>.DQL关键字优先级</span><br><span class="line">select &gt; from &gt; where &gt; group by &gt; having &gt; order by &gt; limit</span><br><span class="line">join:笛卡尔积 类似于两个嵌套循环，表中数据两两组合一条数据 </span><br><span class="line">on：关联查询中的条件判断</span><br><span class="line">left join:左表为主表</span><br><span class="line">union:合并表（匹配不上的字段直接删除）</span><br><span class="line">group by:将符合条件的数据合并成一组 实际上用键值对存储最多一组的分组条件和的个数</span><br><span class="line">where:查询中的条件判断</span><br><span class="line">having:查询后的结果的条件判断</span><br><span class="line">order by:排序 asc(默认：升序，随着序列的上升而上升) desc 降序</span><br><span class="line">limit:限制 limit <span class="number">4</span>,<span class="number">3</span> 从第<span class="number">5</span>行开始截取三条数据</span><br></pre></td></tr></table></figure>
<h3 id="函数部分"><a href="#函数部分" class="headerlink" title="函数部分"></a>函数部分</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//聚合函数什么的不想写了，想偷会懒</span></span><br><span class="line"><span class="comment">//其他的函数也不太熟 这里就先搁置了</span></span><br></pre></td></tr></table></figure>
<h3 id="sql优化"><a href="#sql优化" class="headerlink" title="sql优化"></a>sql优化</h3><h4 id="尽量少触发全表扫描如（就这些吧，太多了也记不住）："><a href="#尽量少触发全表扫描如（就这些吧，太多了也记不住）：" class="headerlink" title="尽量少触发全表扫描如（就这些吧，太多了也记不住）："></a>尽量少触发全表扫描如（就这些吧，太多了也记不住）：</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.where 子句中使用!=或&lt;&gt;操作符 </span><br><span class="line">2.where 及 order by 涉及的列上建立索引 </span><br><span class="line">3.在 where 子句中对字段进行 null 值判断 </span><br><span class="line">4.在 where 子句中使用 or 来连接条件</span><br><span class="line">5.下面的查询也将导致全表扫描：(不能前置百分号) </span><br><span class="line">6.in 和 not in 也要慎用，否则会导致全表扫描 </span><br><span class="line">7.在 where 子句中使用参数</span><br><span class="line"> 可以用 <span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">with</span>(<span class="keyword">index</span>(索引名)) <span class="keyword">where</span> <span class="keyword">num</span>=@<span class="keyword">num</span>(强制使用索引)</span><br><span class="line"><span class="number">8.</span>在<span class="keyword">where</span>子句中对字段进行函数操作</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://justcodingwc.top/2018/11/03/scala入门/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wuchao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codingwc's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/03/scala入门/" itemprop="url">scala入门</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-03T00:28:04+08:00">
                2018-11-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="萧伯纳：计算机除了答案什么都没有。而我就是追求答案的人"><a href="#萧伯纳：计算机除了答案什么都没有。而我就是追求答案的人" class="headerlink" title="萧伯纳：计算机除了答案什么都没有。而我就是追求答案的人"></a>萧伯纳：计算机除了答案什么都没有。而我就是追求答案的人</h2><h3 id="scala语言"><a href="#scala语言" class="headerlink" title="scala语言"></a>scala语言</h3><p>​    scala是一门多范式的编程语言，多范式也就是说有很多的编程规范。设计初衷是实现可伸缩的语言（写的太多比较详细，代码容易阅读，对于熟练地开发者来说写得少可以减少工作量），集成了函数式编程（惰性计算、递归、高阶函数：作用简化编程）与面向对象编程（本质是以建立模型体现出来的抽象思维过程和面向对象的方法。模型是用来反应现实世界事物的特征）。object在大陆的翻译为对象，因此很多程序员开玩笑没对象就new一个吧，object在台湾和香港翻译为物件，泛指世上的一切事物。scala运行于java虚拟机，静态编译（将静态库需要调用的部分中的部分提取出来，链接到文件中，消耗资源多），且兼容java代码。博主开发工具是IDEA（英文单词全部大写，要么是专有名词，要么是单词缩写，列入IT,Internet technology）</p>
<h3 id="声明变量"><a href="#声明变量" class="headerlink" title="声明变量"></a>声明变量</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> i = <span class="number">1</span>(不可变)</span><br><span class="line"><span class="keyword">var</span> s = <span class="string">"hello"</span>(可变)</span><br></pre></td></tr></table></figure>
<h3 id="常用类型"><a href="#常用类型" class="headerlink" title="常用类型"></a>常用类型</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Byte、Char、Short、Int、Long、Float、Double 与java基本数据类型所占字节大小相同 </span></span><br><span class="line"><span class="comment">//一个字节8位（2的8次方），取值范围也能计算出来</span></span><br></pre></td></tr></table></figure>
<h3 id="条件表达式"><a href="#条件表达式" class="headerlink" title="条件表达式"></a>条件表达式</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> y = <span class="keyword">if</span> (x &gt; <span class="number">0</span>) <span class="number">1</span> <span class="keyword">else</span> <span class="number">-1</span></span><br><span class="line"><span class="keyword">val</span> z = <span class="keyword">if</span> (x &gt; <span class="number">1</span>) <span class="number">1</span> <span class="keyword">else</span> <span class="string">"error"</span> 不像java对类型的限制这么严格</span><br></pre></td></tr></table></figure>
<h3 id="块表达式"><a href="#块表达式" class="headerlink" title="块表达式"></a>块表达式</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> result = &#123;</span><br><span class="line"> <span class="number">5</span>  <span class="comment">//块中最后一个表达式的值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i &lt;- 表达式/数组/集合)</span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>) <span class="keyword">yield</span> i * <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- arr)</span><br></pre></td></tr></table></figure>
<h3 id="定义方法（命令式编程更关心解决问题的步骤）"><a href="#定义方法（命令式编程更关心解决问题的步骤）" class="headerlink" title="定义方法（命令式编程更关心解决问题的步骤）"></a>定义方法（命令式编程更关心解决问题的步骤）</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">m2</span> </span>(x:<span class="type">Int</span>):<span class="type">Int</span>=&#123;  <span class="comment">//递归函数必须给返回值</span></span><br><span class="line">    <span class="keyword">if</span>(x&lt;<span class="number">1</span>) <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span> m2(x<span class="number">-1</span>)*x</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="定义函数（函数式编程更关心演算结果）"><a href="#定义函数（函数式编程更关心演算结果）" class="headerlink" title="定义函数（函数式编程更关心演算结果）"></a>定义函数（函数式编程更关心演算结果）</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> f1 = (x:<span class="type">Int</span>,y:<span class="type">Int</span>)=&gt;x+y  <span class="comment">//函数对象有apply、curried、toString、tuple</span></span><br><span class="line"><span class="comment">//如果想把方法转换成一个函数，可以用方法名跟上下划线的方式</span></span><br></pre></td></tr></table></figure>
<h3 id="定义数组、映射、元组"><a href="#定义数组、映射、元组" class="headerlink" title="定义数组、映射、元组"></a>定义数组、映射、元组</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//用来操作数据除了常用类型之外scala还有这些以及集合。</span></span><br><span class="line"><span class="keyword">val</span> arr = <span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> arr = <span class="type">ArrayBuffer</span>[<span class="type">T</span>]() <span class="comment">//import scala.collection.mutable.ArrayBuffer</span></span><br><span class="line">println(arr.toBuffer) <span class="comment">//直接打印打印数组的hash值（hash函数之后得出的地址值）</span></span><br><span class="line">arr += (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>) arr ++= <span class="type">ArrayBuffer</span>(<span class="number">7</span>,<span class="number">8</span>) <span class="comment">//追加 </span></span><br><span class="line">arr.insert(<span class="number">0</span>,<span class="number">-1</span>) arr.remove(<span class="number">0</span>) <span class="comment">//从某个位置插入</span></span><br><span class="line">数组常用算法 arr.sorted 升序  arr.sum arr.max</span><br><span class="line">映射：<span class="keyword">val</span> map=<span class="type">Map</span>((键，值),(键，值),(键，值)....)</span><br><span class="line">获取键= map变量名.keys /map变量名.keySet</span><br><span class="line">获取值= map变量名(键) map变量名.getOrElse(<span class="string">"suke"</span>,<span class="number">0</span>) </span><br><span class="line">增加：+=</span><br><span class="line">删减：-=/map变量名.remove</span><br><span class="line">遍历map方法：</span><br><span class="line"><span class="keyword">for</span>(x&lt;- user.keys) println(x+<span class="string">" -&gt; "</span>+user(x))</span><br><span class="line"><span class="keyword">for</span>((x,y) &lt;- user) println(x+<span class="string">" -&gt; "</span>+y)</span><br><span class="line">user.foreach&#123;<span class="keyword">case</span> (x,y) =&gt; println(x+<span class="string">" -&gt; "</span>+y)&#125;</span><br><span class="line"><span class="comment">//import scala.collection.mutable/immutable.Map</span></span><br><span class="line">元组：<span class="keyword">val</span> t = (<span class="string">"hadoop"</span>,<span class="number">3.14</span>,<span class="number">5</span>) <span class="comment">//下标从1开始 可以调用toMap转成map</span></span><br></pre></td></tr></table></figure>
<h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.immutable/mutable._ (可变和不可变序列)</span><br><span class="line"><span class="keyword">val</span> list0 = <span class="type">ListBuffer</span>[<span class="type">Int</span>](<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> list1 = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>) </span><br><span class="line"><span class="keyword">val</span> other_lst=<span class="number">2</span>::<span class="type">Nil</span> <span class="comment">//:: 操作符是右结合的</span></span><br><span class="line">list.remove/-= <span class="comment">//删 </span></span><br><span class="line">list.add/+= <span class="comment">//增 </span></span><br><span class="line"><span class="keyword">import</span> scala.collection.immutable/mutable._</span><br><span class="line"><span class="keyword">val</span> set1=<span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Int</span>]()</span><br><span class="line">set.add/+=<span class="comment">//增</span></span><br><span class="line">set.remove/+=<span class="comment">//删</span></span><br></pre></td></tr></table></figure>
<h3 id="类、对象、继承、特质"><a href="#类、对象、继承、特质" class="headerlink" title="类、对象、继承、特质"></a>类、对象、继承、特质</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Scala中的每个类都有主构造器，主构造器的参数直接放置类名后面，与类交织在一起。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params">val name:<span class="type">String</span>,var age:<span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="comment">//主构造器会执行类定义的所有语句</span></span><br><span class="line">  println(<span class="string">"执行主构造器"</span>)</span><br><span class="line">  <span class="keyword">private</span>  <span class="keyword">var</span> gender=<span class="string">"male"</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(name:<span class="type">String</span>,age:<span class="type">Int</span>,gender:<span class="type">String</span>)&#123;</span><br><span class="line">    <span class="comment">//每个辅助构造器执行必须以主构造器或者其他辅助构造器的调用开始</span></span><br><span class="line">    <span class="keyword">this</span>(name,age)</span><br><span class="line">    println(<span class="string">"执行辅助构造器"</span>)</span><br><span class="line">    <span class="keyword">this</span>.gender=gender</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">相当于</span> <span class="title">class</span> <span class="title">的单个实例，通常在里面放一些静态的</span> <span class="title">field</span> <span class="title">或者</span> <span class="title">method</span></span>:</span><br><span class="line"><span class="number">1.</span>存放工具方法</span><br><span class="line"><span class="number">2.</span>高效共享单个不可变的实例</span><br><span class="line"><span class="number">3.</span>单例模式</span><br><span class="line">伴生对象：可以互相访问</span><br></pre></td></tr></table></figure>
<h3 id="trait"><a href="#trait" class="headerlink" title="trait"></a>trait</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">MakeFriendsTrait</span> </span>&#123;  <span class="comment">//与java接口相似</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">makeFriends</span></span>(c: <span class="type">Children</span>): <span class="type">Unit</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="模式匹配与样例类"><a href="#模式匹配与样例类" class="headerlink" title="模式匹配与样例类"></a>模式匹配与样例类</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//类似于switch</span></span><br><span class="line"><span class="comment">//样例类 case class 多例要跟参数 case object 单例</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">HeartBeat</span>(<span class="params">time: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">object</span> <span class="title">CheckTimeOutTask</span></span></span><br></pre></td></tr></table></figure>
<h3 id="协变、逆变、非变"><a href="#协变、逆变、非变" class="headerlink" title="协变、逆变、非变"></a>协变、逆变、非变</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//C[+T]：如果A是B的子类，那么C[A]是C[B]的子类。</span></span><br><span class="line"><span class="comment">//C[-T]：如果A是B的子类，那么C[B]是C[A]的子类。</span></span><br><span class="line"><span class="comment">//C[T]： 无论A和B是什么关系，C[A]和C[B]没有从属关系。</span></span><br></pre></td></tr></table></figure>
<h3 id="上下界"><a href="#上下界" class="headerlink" title="上下界"></a>上下界</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//(1) U &gt;: T</span></span><br><span class="line"><span class="comment">//这是类型下界的定义，也就是U必须是类型T的父类(或本身，自己也可以认为是自己的父类)。</span></span><br><span class="line"><span class="comment">//(2) S &lt;: T</span></span><br><span class="line"><span class="comment">//这是类型上界的定义，也就是S必须是类型T的子类（或本身，自己也可以认为是自己的子类)。</span></span><br></pre></td></tr></table></figure>
<h3 id="Actor"><a href="#Actor" class="headerlink" title="Actor"></a>Actor</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//类似于rpc框架和socket编程的结合</span></span><br><span class="line"><span class="comment">//需要样例匹配和样例类</span></span><br></pre></td></tr></table></figure>
<h3 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//函数可以作为值传递、可以没有函数名 函数的颗粒化（柯里化）：分拆函数为多个输入函数</span></span><br><span class="line"><span class="comment">//闭包：闭包是一个函数，返回值依赖于声明在函数外部的一个或多个变量。</span></span><br><span class="line"> <span class="keyword">val</span> add=(x:<span class="type">Int</span>)=&gt;&#123;</span><br><span class="line"> 	x+y<span class="comment">//y外部变量</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h3 id="隐式转换"><a href="#隐式转换" class="headerlink" title="隐式转换"></a>隐式转换</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//所有的隐式值和隐式方法必须放到object</span></span><br><span class="line"><span class="comment">//对象调用不存在的方法和成员，转换为已知的方法和成员（包括类型）</span></span><br><span class="line"><span class="comment">//同一类型的隐式值只允许出现一次，否则会报错</span></span><br><span class="line"><span class="comment">//使用import导入</span></span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//明天开始更hive 头一回写这个 以后可能会写心情博客    </span></span><br><span class="line"><span class="comment">//人世间的悲欢并不想通，我只是觉得有些吵闹</span></span><br><span class="line"><span class="comment">//也许以后会更其他博客，例如对生活对名人以及书本的一些解读</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">wuchao</p>
              <p class="site-description motion-element" itemprop="description">you never konw what's the next</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wuchao</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
